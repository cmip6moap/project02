{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "####################################################################################################################\n",
    "Program    : calc_seasonal_means.ipynb\n",
    "Usage      : Reads in numpy dictionary containing CMIP6 multi-model monthly precipitation data for a specified \n",
    "             region, and calculates the seasonal mean for each model for selected time period (historical or future).\n",
    "             Output is a number of .npy files containing data for all models.\n",
    "Written in : Python\n",
    "Tested on  : JASMIN\n",
    "Written by : Natalie Lord (natalie.lord@bristol.ac.uk), with some code adapted from script written by Jess Baker (j.c.baker@leeds.ac.uk)  \n",
    "Date       : 03/06/2021\n",
    "####################################################################################################################\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import datetime as dt\n",
    "from pathlib import Path\n",
    "import iris\n",
    "import iris.coord_categorisation\n",
    "from iris.experimental.equalise_cubes import equalise_attributes\n",
    "from iris.util import unify_time_units\n",
    "from iris.time import PartialDateTime\n",
    "import iris.analysis.cartography\n",
    "import cftime\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import datetime\n",
    "\n",
    "\n",
    "def make_cmip6_filepath(directory_nam, # scenario, variable, data_type, experiment, region,\n",
    "                        data_root=\"/home/users/nat_lord/cmip6_hackathon/data\"):\n",
    "    \"\"\"\n",
    "    Make a file path for a cmip6 dataset on JASMIN for a single variable\n",
    "    \"\"\"\n",
    "    # get base path\n",
    "    path = str(DATA_ROOT / directory_nam) # / data_type / model)\n",
    "    #print(path)\n",
    "    #print(os.listdir(path))\n",
    "    \n",
    "    print('JASMIN FILEPATH:')\n",
    "    print(path)\n",
    "    print('DIRECTORY CONTENTS:')\n",
    "    print(os.listdir(path))\n",
    "    return(path+ '/')\n",
    "\n",
    "def make_cmip6_filenam(file_prefix, experiment, variable, latmin, latmax, lonmin, lonmax):\n",
    "    \"\"\"\n",
    "    Make a file path for a cmip6 dataset on JASMIN for a single variable\n",
    "    \"\"\"\n",
    "    file = str(file_prefix + '_' + experiment + '_' + variable + '_dict' + str(latmin) + '_to_' + str(latmax) + 'lat' + '_' + str(lonmin)  + '_to_' + str(lonmax)  + 'lon')\n",
    "    \n",
    "    print('JASMIN FILENAM:')\n",
    "    print(file)\n",
    "    return(file+ '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of models and institutes (allows you to loop over models and know the name of the directory that contains the data for that model)\n",
    "basepath = '/badc/cmip6/data/CMIP6/CMIP/'\n",
    "institute_list = os.listdir(basepath)\n",
    "model_inst_dict = {}\n",
    "\n",
    "# loop over institutes\n",
    "for inst in institute_list:\n",
    "    model_list = os.listdir(basepath + inst + '/')\n",
    "    \n",
    "    # for each institute list models and store in dictionary\n",
    "    for model_temp in model_list:\n",
    "        model_inst_dict[model_temp] = inst\n",
    "    \n",
    "    # correction for UKESM which is used by multiple centres - we want MOHC only\n",
    "    model_inst_dict['UKESM1-0-LL'] = 'MOHC'\n",
    "    \n",
    "# print(model_inst_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JASMIN FILEPATH:\n",
      "/home/users/nat_lord/cmip6_hackathon/data/CMIP6histo\n",
      "DIRECTORY CONTENTS:\n",
      "['zonalAverages', 'cmip6_historical_pr_dict.npy', 'cmip6_historical_pr_dict-40_to_40lat_-20_to_50lon.npy', 'cmip6_historical_pr_dict-90_to_90lat_-180_to_180lon.npy', 'global']\n",
      "JASMIN FILENAM:\n",
      "cmip6_historical_pr_dict-90_to_90lat_-180_to_180lon\n"
     ]
    }
   ],
   "source": [
    "#assert False  # May want to add this if already saved data into dictionaries to prevent re-writing\n",
    "\n",
    "# Read in precipitation data over domain for CMIP6 models and save data to dictionary\n",
    "\n",
    "DATA_ROOT = Path(\"/home/users/nat_lord/cmip6_hackathon/data/\")\n",
    "#DATA_ROOT = Path(\"/gws/pw/j05/cop26_hackathons/bristol/project02/data/\")\n",
    "\n",
    "# dictionary to save subset model output\n",
    "pr_datasets_seas_means = {}\n",
    "pr_datasets_seas_means_av = {}\n",
    "\n",
    "# Define region of interest\n",
    "latmin = -90 #-40\n",
    "latmax = 90 #40\n",
    "lonmin = -180 #-20\n",
    "lonmax = 180 #50\n",
    "\n",
    "# variables for JASMIN directory structure\n",
    "table_id = 'Amon'  # monthly model output\n",
    "variable_id = 'pr'  # variable code for precipitation in cmip6 model output\n",
    "\n",
    "# read in monthly zonal data \n",
    "\n",
    "# Larger selection of models\n",
    "models = ['ACCESS-CM2', 'ACCESS-ESM1-5', 'BCC-CSM2-MR', 'CAMS-CSM1-0', 'CanESM5',\n",
    "          'CNRM-CM6-1', 'CNRM-ESM2-1', 'FGOALS-f3-L', 'FGOALS-g3', 'HadGEM3-GC31-MM',\n",
    "          'GISS-E2-1-G', 'INM-CM5-0', 'INM-CM4-8',\n",
    "          'MPI-ESM1-2-LR', 'NorESM2-LM', 'NorESM2-MM', 'TaiESM1', 'UKESM1-0-LL'] \n",
    "\n",
    "# Subset of models that have SSP119 data available\n",
    "#models = ['CAMS-CSM1-0', 'CanESM5',\n",
    "#          'CNRM-ESM2-1', 'FGOALS-g3',\n",
    "#          'GISS-E2-1-G', \n",
    "#          'UKESM1-0-LL'] \n",
    "\n",
    "# Try for just one model to see if it works\n",
    "#models = ['CanESM5', 'UKESM1-0-LL']\n",
    "\n",
    "# Loop over multiple model experiments and calculate SPEI for all, north and south Ghana\n",
    "for expt in ['historical']: #, 'historical', ssp119', 'ssp585']:\n",
    "\n",
    "    try:\n",
    "        # get CMIP6 precip data\n",
    "        if expt == 'historical':\n",
    "            scenario = 'CMIP'\n",
    "            file_prefix = 'cmip6'\n",
    "            directory_nam = str('CMIP6' + 'histo')\n",
    "            first_yr = 's1850'\n",
    "\n",
    "            start_year = 1970 #1970\n",
    "            end_year = 1999 #2000\n",
    "\n",
    "        elif expt in ['ssp119', 'ssp126', 'ssp245', 'ssp370', 'ssp585']:\n",
    "            scenario = 'CMIP'\n",
    "            file_prefix = 'cmip6'\n",
    "            directory_nam = str('CMIP6' + 'proj')\n",
    "            first_yr = 's2015'\n",
    "#            scenario = 'ScenarioMIP'\n",
    "\n",
    "            start_year = 2070 #2070\n",
    "            end_year = 2099 #2100\n",
    "\n",
    "#        time_period_subset = str(str(start_year) + '-' + str(end_year))\n",
    "\n",
    "        # get filepath for data for particular model and variable of interest\n",
    "        fp_nam_path = make_cmip6_filepath(directory_nam=directory_nam)\n",
    "        fp_nam_file = make_cmip6_filenam(file_prefix=file_prefix, experiment=expt, variable=variable_id, latmin=latmin, latmax=latmax, lonmin=lonmin, lonmax=lonmax) \n",
    "            \n",
    "        fp_nam = str(str(fp_nam_path) + '/' + fp_nam_file)\n",
    "            \n",
    "        # read in data\n",
    "        pr_data_all = np.load(fp_nam).item()\n",
    "            \n",
    "#        print(pr_data_all)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(model, ' has no ' + expt.upper() + ' output')\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2  HISTORICAL\n",
      "Calculating seasonal averages for  model data\n",
      "Extracting data for specified time period\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jaspy/lib/python3.7/site-packages/iris/coords.py:1355: UserWarning: Collapsing a non-contiguous coordinate. Metadata may not be fully descriptive for 'time'.\n",
      "  warnings.warn(msg.format(self.name()))\n",
      "/opt/jaspy/lib/python3.7/site-packages/iris/coords.py:1355: UserWarning: Collapsing a non-contiguous coordinate. Metadata may not be fully descriptive for 'season_year'.\n",
      "  warnings.warn(msg.format(self.name()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-ESM1-5  HISTORICAL\n",
      "Calculating seasonal averages for  model data\n",
      "Extracting data for specified time period\n",
      "BCC-CSM2-MR  HISTORICAL\n",
      "Calculating seasonal averages for  model data\n",
      "Extracting data for specified time period\n",
      "CAMS-CSM1-0  HISTORICAL\n",
      "Calculating seasonal averages for  model data\n",
      "Extracting data for specified time period\n",
      "CanESM5  HISTORICAL\n",
      "Calculating seasonal averages for  model data\n",
      "Extracting data for specified time period\n",
      "CNRM-CM6-1  HISTORICAL\n",
      "Calculating seasonal averages for  model data\n",
      "Extracting data for specified time period\n",
      "CNRM-ESM2-1  HISTORICAL\n",
      "Calculating seasonal averages for  model data\n",
      "Extracting data for specified time period\n",
      "FGOALS-f3-L  HISTORICAL\n",
      "Calculating seasonal averages for  model data\n",
      "Extracting data for specified time period\n",
      "FGOALS-g3  HISTORICAL\n",
      "Calculating seasonal averages for  model data\n",
      "Extracting data for specified time period\n",
      "HadGEM3-GC31-MM  HISTORICAL\n",
      "Calculating seasonal averages for  model data\n",
      "Extracting data for specified time period\n",
      "GISS-E2-1-G  HISTORICAL\n",
      "Calculating seasonal averages for  model data\n",
      "Extracting data for specified time period\n",
      "INM-CM5-0  HISTORICAL\n",
      "Calculating seasonal averages for  model data\n",
      "Extracting data for specified time period\n",
      "INM-CM4-8  HISTORICAL\n",
      "Calculating seasonal averages for  model data\n",
      "Extracting data for specified time period\n",
      "MPI-ESM1-2-LR  HISTORICAL\n",
      "Calculating seasonal averages for  model data\n",
      "Extracting data for specified time period\n",
      "NorESM2-LM  HISTORICAL\n",
      "Calculating seasonal averages for  model data\n",
      "Extracting data for specified time period\n",
      "NorESM2-MM  HISTORICAL\n",
      "Calculating seasonal averages for  model data\n",
      "Extracting data for specified time period\n",
      "TaiESM1  HISTORICAL\n",
      "Calculating seasonal averages for  model data\n",
      "Extracting data for specified time period\n",
      "UKESM1-0-LL  HISTORICAL\n",
      "Calculating seasonal averages for  model data\n",
      "Extracting data for specified time period\n",
      "SAVING TO: /home/users/nat_lord/cmip6_hackathon/data/CMIP6histo/global/pr_seas_1970-1999_historical_-90_to_90lat_-180_to_180lon\n",
      "pr_seas_1970-1999_historical_-90_to_90lat_-180_to_180lon\n",
      "SAVING TO: /home/users/nat_lord/cmip6_hackathon/data/CMIP6histo/global/pr_seas_1970-1999av_historical_-90_to_90lat_-180_to_180lon\n",
      "pr_seas_1970-1999av_historical_-90_to_90lat_-180_to_180lon\n"
     ]
    }
   ],
   "source": [
    "    for model in models:\n",
    "        print(model, '', expt.upper())\n",
    "\n",
    "        # extract data for individual models\n",
    "        model_time = pr_data_all[model].coord('time')\n",
    "        model_lat = pr_data_all[model].coord('latitude')\n",
    "        model_lon = pr_data_all[model].coord('lon')\n",
    "\n",
    "        # print(pr_data)\n",
    "#        print(model_time)\n",
    "#        print(model_lat)\n",
    "#        print(model_lon)\n",
    "\n",
    "        # Model data - calculate seasonal data\n",
    "        print('Calculating seasonal averages for  model data')\n",
    "\n",
    "        iris.coord_categorisation.add_season(pr_data_all[model], 'time', name='clim_season')\n",
    "        iris.coord_categorisation.add_season_year(pr_data_all[model], 'time', name='season_year')\n",
    "\n",
    "        pr_cube_seas_mean = pr_data_all[model].aggregated_by(\n",
    "                                     ['clim_season', 'season_year'], \n",
    "                                     iris.analysis.MEAN)\n",
    "\n",
    "        tdelta_3mth = datetime.timedelta(days=3*28)\n",
    "        spans_three_months = lambda t: (t.bound[1] - t.bound[0]) > tdelta_3mth\n",
    "        three_months_bound = iris.Constraint(time=spans_three_months)\n",
    "\n",
    "        ### CHECK IF ALL SEASONS HAVE 3 MONTHS ###\n",
    "        # pr_cube_full_seas_mean = pr_cube_seas_mean.extract(three_months_bound)\n",
    "\n",
    "        view_data = pr_cube_seas_mean \n",
    "#        for season, year in zip(view_data.coord('clim_season')[:10].points,\n",
    "#            view_data.coord('season_year')[:10].points):\n",
    "#            print(season + ' ' + str(year))\n",
    "            \n",
    "            \n",
    "        # Select data for specific time period\n",
    "        print('Extracting data for specified time period')\n",
    "        pdt1 = PartialDateTime(year=start_year, month=1) # Include preceding year to allow DJF calculation\n",
    "        pdt2 = PartialDateTime(year=end_year, month=12)\n",
    "\n",
    "        pr_cube_seas_mean_time_subset = pr_cube_seas_mean.extract(iris.Constraint(time=lambda cell: pdt1 <= cell.point <= pdt2))\n",
    "#        print(pr_cube_seas_mean_time_subset)\n",
    "\n",
    "        time_model_subset = pr_cube_seas_mean_time_subset.coord('time')\n",
    "        time_model_dates_subset = cftime.num2date(time_model_subset.points,time_model_subset.units.origin,calendar=time_model_subset.units.calendar) #'days since 1850-01-01'\n",
    "#        print(time_model_subset)\n",
    "\n",
    "\n",
    "        pr_cube_djf_seas_mean = pr_cube_seas_mean_time_subset.extract(iris.Constraint(clim_season='djf'))\n",
    "        pr_cube_mam_seas_mean = pr_cube_seas_mean_time_subset.extract(iris.Constraint(clim_season='mam'))\n",
    "        pr_cube_jja_seas_mean = pr_cube_seas_mean_time_subset.extract(iris.Constraint(clim_season='jja'))\n",
    "        pr_cube_son_seas_mean = pr_cube_seas_mean_time_subset.extract(iris.Constraint(clim_season='son'))\n",
    "#        print(pr_cube_djf)\n",
    "        \n",
    "        \n",
    "        # Calculate seasonal average across time period\n",
    "        pr_cube_djf_seas_mean_av = pr_cube_djf_seas_mean.collapsed(['time', 'clim_season', 'season_year'], iris.analysis.MEAN)\n",
    "#        print(pr_cube_djf_seas_mean_av)\n",
    "\n",
    "        \n",
    "        pr_datasets_seas_means[model] = pr_cube_seas_mean_time_subset\n",
    "        pr_datasets_seas_means_av[model] = pr_cube_djf_seas_mean_av\n",
    "        \n",
    "        \n",
    "    # change output directory to somewhere you can save\n",
    "    outpath = '/home/users/nat_lord/cmip6_hackathon/data/'\n",
    "    data_type = 'global'  # directory\n",
    "    data_nam2 = 'seas'  # directory\n",
    "    fname = str(variable_id + '_' + data_nam2 + '_' + str(start_year) + '-' + str(end_year) + '_' + expt + '_' + str(latmin) + '_to_' + str(latmax) + 'lat' + '_' + str(lonmin)  + '_to_' + str(lonmax)  + 'lon')\n",
    "    print('SAVING TO:', outpath + directory_nam + '/' + data_type + '/' + fname)\n",
    "    print(fname)\n",
    "    if os.path.exists(outpath + directory_nam + '/' + data_type + '/' + fname):\n",
    "        os.remove(outpath + directory_nam + '/' + data_type + '/' + fname)\n",
    "#    np.save(outpath + directory_nam + '/' + data_type + '/' + fname, pr_datasets_seas_means)  # uncomment to save\n",
    "\n",
    "    \n",
    "    # change output directory to somewhere you can save\n",
    "    outpath = '/home/users/nat_lord/cmip6_hackathon/data/'\n",
    "    data_type = 'global'  # directory\n",
    "    data_nam = 'av'  # directory\n",
    "    data_nam2 = 'seas'  # directory\n",
    "    fname = str(variable_id + '_' + data_nam2 + '_' + str(start_year) + '-' + str(end_year) + data_nam + '_' + expt + '_' + str(latmin) + '_to_' + str(latmax) + 'lat' + '_' + str(lonmin)  + '_to_' + str(lonmax)  + 'lon')\n",
    "    print('SAVING TO:', outpath + directory_nam + '/' + data_type + '/' + fname)\n",
    "    print(fname)\n",
    "    if os.path.exists(outpath + directory_nam + '/' + data_type + '/' + fname):\n",
    "        os.remove(outpath + directory_nam + '/' + data_type + '/' + fname)\n",
    "#    np.save(outpath + directory_nam + '/' + data_type + '/' + fname, pr_datasets_seas_means_av)  # uncomment to save\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
